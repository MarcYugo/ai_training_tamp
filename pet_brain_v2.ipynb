{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5bdac27-bf4b-49cb-9a42-4b3fa51f25a0",
   "metadata": {},
   "source": [
    "### 依赖安装 shell 脚本 repes_install.sh\n",
    "```bash\n",
    "# 内容\n",
    "pip install nibabel\n",
    "pip install albumentations\n",
    "mkdir logs model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71d52cc2-60cc-4e25-aa06-b041adeaaffd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-25T04:57:15.574099Z",
     "iopub.status.busy": "2023-08-25T04:57:15.573650Z",
     "iopub.status.idle": "2023-08-25T04:57:15.580870Z",
     "shell.execute_reply": "2023-08-25T04:57:15.579927Z",
     "shell.execute_reply.started": "2023-08-25T04:57:15.574073Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !bash repes_install.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf6033d-c041-4c00-8a71-ad2a8257ee91",
   "metadata": {},
   "source": [
    "### 数据载入与增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0535d13-37b3-4cca-9c05-d91420b2661e",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T04:57:15.582850Z",
     "iopub.status.busy": "2023-08-25T04:57:15.582601Z",
     "iopub.status.idle": "2023-08-25T04:57:17.724925Z",
     "shell.execute_reply": "2023-08-25T04:57:17.724111Z",
     "shell.execute_reply.started": "2023-08-25T04:57:15.582829Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 dataset\r"
     ]
    }
   ],
   "source": [
    "import os, sys, glob, argparse,random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from functools import reduce\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as TRANS\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "import nibabel as nib\n",
    "from nibabel.viewers import OrthoSlicer3D\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "trn_path1 = glob.glob('./reset_pet_brain/Train/NC/*')\n",
    "trn_path2 = glob.glob('./reset_pet_brain/Train/MCI/*')\n",
    "test_path = glob.glob('./reset_pet_brain/Test/*')\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(trn_path1)\n",
    "np.random.shuffle(trn_path2)\n",
    "np.random.shuffle(test_path)\n",
    "train_path = trn_path1+trn_path2\n",
    "\n",
    "DATA_CACHE = {}\n",
    "class XunFeiDataset(Dataset):\n",
    "    def __init__(self, img_path, transform=None,tgt_ch=64):\n",
    "        self.img_path = img_path\n",
    "        self.chs = tgt_ch\n",
    "        if transform is not None:\n",
    "            self.transform = transform\n",
    "        else:\n",
    "            self.transform = None\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.img_path[index] in DATA_CACHE:\n",
    "            img = DATA_CACHE[self.img_path[index]]\n",
    "        else:\n",
    "            img = nib.load(self.img_path[index])\n",
    "            img = img.dataobj[...,0]\n",
    "            img = img.astype(np.float32)\n",
    "            for i in range(img.shape[-1]):\n",
    "                img[:,:,i] = (img[:,:,i] - img[:,:,i].mean())/(img[:,:,i].std())\n",
    "            DATA_CACHE[self.img_path[index]] = img\n",
    "        x,y,z = img.shape\n",
    "        s = 0\n",
    "        e = int(z*0.7) + 1\n",
    "        z = e - s\n",
    "        idxl = list(range(s,e))\n",
    "        if self.chs > z:\n",
    "            idx = idxl*(self.chs//z)\n",
    "            if self.chs%z > 0:\n",
    "                idx += list(np.random.choice(idxl, self.chs%z,replace=False))\n",
    "        else:\n",
    "            idx = list(np.random.choice(idxl, self.chs,replace=False))\n",
    "        idx.sort()\n",
    "        img = img[:, :, idx]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(image = img)['image']\n",
    "        img = img.transpose([2,0,1]) # (z',x',y')\n",
    "        return img,torch.from_numpy(np.array(int('NC' in self.img_path[index])))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "\n",
    "'''\n",
    "    因为训练集太少，增加K折交叉验证降低数据集划分时的偶然性（验证集分布与测试集分布差距较大）\n",
    "    参与训练集数据仅有 15 × 2 = 30 个，验证集数据 10 × 2 = 20 个\n",
    "'''\n",
    "import albumentations as A\n",
    "\n",
    "transforms = {\n",
    "    'train': A.Compose([A.Resize(128,128),\n",
    "                        A.CenterCrop(100, 100)]),\n",
    "    'val': A.Compose([A.Resize(128,128),\n",
    "                      A.CenterCrop(100, 100)]),\n",
    "    'test': A.Compose([A.Resize(128,128),\n",
    "                       A.CenterCrop(100, 100)])\n",
    "}\n",
    "\n",
    "def make_loader(paths,loader_type='train'):\n",
    "    loader = None\n",
    "    if loader_type == 'train':\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "                        XunFeiDataset(paths,transforms[loader_type]), \n",
    "                        batch_size=2, shuffle=True, num_workers=1, pin_memory=False)\n",
    "    elif loader_type == 'val':\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "                        XunFeiDataset(paths,transforms[loader_type]), \n",
    "                        batch_size=2, shuffle=False, num_workers=1, pin_memory=False)\n",
    "    elif loader_type == 'test':\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "                        XunFeiDataset(paths,transforms[loader_type]), \n",
    "                        batch_size=2, shuffle=False, num_workers=1, pin_memory=False)\n",
    "    return loader\n",
    "\n",
    "KFold_loaders = {}\n",
    "n_splits = 10\n",
    "kfold = KFold(n_splits=n_splits,shuffle=True,random_state=0)\n",
    "train_path = np.array(train_path)\n",
    "test_loader = make_loader(test_path,'test')\n",
    "\n",
    "for i,(trn_indx,val_indx) in enumerate(kfold.split(train_path)):\n",
    "    trn_paths = train_path[trn_indx]\n",
    "    val_paths = train_path[val_indx]\n",
    "    trn_loader = make_loader(trn_paths,'train')\n",
    "    val_loader = make_loader(val_paths,'val')\n",
    "    KFold_loaders[f'KFold{i:02}'] = (trn_loader,val_loader)\n",
    "    print(f'{i+1:02}/{n_splits} dataset',end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda896c8-9a24-4ba2-8d8e-589fd7a82d48",
   "metadata": {},
   "source": [
    "### 训练与验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3dfdb37-513f-402d-af36-25ff173a783c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T04:57:17.881158Z",
     "iopub.status.busy": "2023-08-25T04:57:17.880522Z",
     "iopub.status.idle": "2023-08-25T04:57:17.891139Z",
     "shell.execute_reply": "2023-08-25T04:57:17.890402Z",
     "shell.execute_reply.started": "2023-08-25T04:57:17.881130Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for i, (inputs, target) in enumerate(train_loader):\n",
    "        inputs = inputs.cuda(non_blocking=True)\n",
    "        target = target.cuda(non_blocking=True)\n",
    "\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    return train_loss/len(train_loader)\n",
    "            \n",
    "def validate(val_loader, model, criterion):\n",
    "    model.eval()\n",
    "    val_acc = 0.0\n",
    "    f1_sc = 0.\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, target) in enumerate(val_loader):\n",
    "            inputs = inputs.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(inputs)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            val_acc += (output.argmax(1) == target).sum().item()\n",
    "            # print(output.argmax(1).shape,target.shape)\n",
    "            if i == 0:\n",
    "                pred = output.argmax(1)\n",
    "                tgt = target\n",
    "            else:\n",
    "                pred = torch.cat((pred,output.argmax(1)),axis=0)\n",
    "                tgt = torch.cat((tgt,target),axis=0)\n",
    "        f1_sc = f1_score(pred.cpu().numpy(),tgt.cpu().numpy())\n",
    "            \n",
    "    return val_acc / len(val_loader.dataset),f1_sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc50d11-a8f0-406b-9e1c-e777c1133e9c",
   "metadata": {},
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b892b7f0-1c84-4b41-8a83-c65df3e46fac",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T04:57:17.903890Z",
     "iopub.status.busy": "2023-08-25T04:57:17.903622Z",
     "iopub.status.idle": "2023-08-25T04:57:20.905078Z",
     "shell.execute_reply": "2023-08-25T04:57:20.904214Z",
     "shell.execute_reply.started": "2023-08-25T04:57:17.903869Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretrain_models = {\n",
    "    'resnet18': models.resnet18,\n",
    "    'resnet34': models.resnet34,\n",
    "    'resnet50': models.resnet50,\n",
    "    'vit_b_16': models.vit_b_16,\n",
    "    'convnext_tiny': models.convnext_tiny,\n",
    "}\n",
    "\n",
    "pretrain_params = {\n",
    "    'resnet18': models.ResNet18_Weights.IMAGENET1K_V1,\n",
    "    'resnet34': models.ResNet34_Weights.IMAGENET1K_V1,\n",
    "    'resnet50': models.ResNet50_Weights.IMAGENET1K_V1,\n",
    "    'vit_b_16': models.ViT_B_16_Weights.IMAGENET1K_SWAG_E2E_V1,\n",
    "    'convnext_tiny': models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1,\n",
    "}\n",
    "\n",
    "class XunFeiNet(nn.Module):\n",
    "    def __init__(self,pretrain='resnet18'):\n",
    "        super(XunFeiNet, self).__init__()\n",
    "        model = pretrain_models[pretrain](weights=pretrain_params[pretrain])\n",
    "        if pretrain == 'resnet50':\n",
    "            model.conv1 = torch.nn.Conv2d(64, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False,groups=64)\n",
    "            model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "            model.fc = nn.Sequential(\n",
    "                        nn.Dropout(0.3),\n",
    "                        nn.Linear(2048, 2)\n",
    "                        )\n",
    "        elif pretrain == 'vit_b_16':\n",
    "            model.conv_proj = torch.nn.Conv2d(32,768,kernel_size=(16,16),stride=(16,16))\n",
    "            model.heads.head = torch.nn.Linear(in_features=768,out_features=2)\n",
    "        elif pretrain in ['convnext_tiny','convnext_small']:\n",
    "            model.features[0][0] = torch.nn.Conv2d(32,96,kernel_size=(4,4),stride=(4,4))\n",
    "            model.classifier[2] = torch.nn.Linear(in_features=768, out_features=2)\n",
    "        elif pretrain in ['resnet18','resnet34']:\n",
    "            model.conv1 = nn.Sequential(\n",
    "                            nn.Conv2d(64,128, kernel_size=3, padding=1),\n",
    "                            nn.Conv2d(128, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)))\n",
    "            model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "            model.fc = nn.Sequential(\n",
    "                    nn.Dropout(0.1),\n",
    "                    nn.Linear(512, 2)\n",
    "                    )\n",
    "        else:\n",
    "            pass\n",
    "        self.net = model\n",
    "        \n",
    "    def forward(self, img):\n",
    "        out = self.net(img)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaddec9-22c5-488d-88ce-9255fc645932",
   "metadata": {},
   "source": [
    "### 进行训练并记录\n",
    "分别使用 resnet18，resnet34，resnet50, vit 和 convnext_tiny 的预训练模型进行训练和识别任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "688e5bbb-5472-4715-bc6b-46e50cd6ab32",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T04:57:20.906774Z",
     "iopub.status.busy": "2023-08-25T04:57:20.906187Z",
     "iopub.status.idle": "2023-08-25T04:57:20.915269Z",
     "shell.execute_reply": "2023-08-25T04:57:20.914580Z",
     "shell.execute_reply.started": "2023-08-25T04:57:20.906751Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "class HisRecorder:\n",
    "    def __init__(self,log_name='test'):\n",
    "        self.name = log_name\n",
    "        self.history = {}\n",
    "        t = datetime.now().strftime('%Y-%m-%d-%H-%M')\n",
    "        fname = self.name + '_' + t\n",
    "        self.fname = fname\n",
    "    def record_info(self,epoch,train_loss,train_acc,val_acc,trn_f1sc,val_f1sc):\n",
    "        self.history[epoch] = (train_loss,train_acc,val_acc,trn_f1sc,val_f1sc)\n",
    "    def save_hist(self):\n",
    "        f = open('./logs/'+self.fname,'w',encoding='utf-8')\n",
    "        f.write(str(self.history))\n",
    "        f.close()\n",
    "        print(self.fname)\n",
    "    def clean_hist(self):\n",
    "        self.history = {}\n",
    "\n",
    "class CheckSaver:\n",
    "    def __init__(self,name):\n",
    "        self.val_best_acc = 0.\n",
    "        self.trn_best_acc = 0.\n",
    "        self.val_best_f1sc = 0.\n",
    "        self.name = name\n",
    "        \n",
    "    def save_check(self,model,optim,sche,trn_acc,val_acc,val_f1_sc,epoch):\n",
    "        flag = self.val_best_f1sc == val_f1_sc and self.val_best_acc <= val_acc\n",
    "        flag = self.val_best_f1sc < val_f1_sc or flag\n",
    "        if flag:\n",
    "            self.val_best_f1sc = val_f1_sc\n",
    "            self.val_best_acc = val_acc\n",
    "            self.trn_best_acc = trn_acc\n",
    "            stat = {\n",
    "                    'epoch': epoch,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'best_acc': val_acc,\n",
    "                    'best_f1_sc': val_f1_sc,\n",
    "                    'optimizer' : optim.state_dict(),\n",
    "                    'scheduler' : sche.state_dict()\n",
    "                }\n",
    "            torch.save(stat,f'./model/{self.name}_best.pth.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133d6de3-2ec9-4694-b35f-aa5ddc79e95d",
   "metadata": {},
   "source": [
    "#### 训练设置\n",
    "一共迭代训练 100 次。起始学习率 设置为 0.0001，之后在训练中使用 CosineAnnealingLR 对学习率进行调整。优化器 使用 AdamW。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5815ad-b448-449a-ab64-1d3d63a0efed",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-08-25T04:57:20.916495Z",
     "iopub.status.busy": "2023-08-25T04:57:20.916249Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i,key in enumerate(KFold_loaders):\n",
    "    pretrain = 'resnet18'\n",
    "    epochs = 100\n",
    "    model = XunFeiNet(pretrain)\n",
    "    model = model.to('cuda')\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), 0.0005)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,epochs+1)\n",
    "    recorder = HisRecorder(pretrain+f'_kfold{i+1:02}')\n",
    "    che_saver = CheckSaver(pretrain+f'_kfold{i+1:02}')\n",
    "    train_loader,val_loader = KFold_loaders[key]\n",
    "    \n",
    "    for epoch  in range(1,epochs+1):\n",
    "        train_loss = train(train_loader, model, criterion, optimizer)\n",
    "        val_acc,val_f1_sc  = validate(val_loader, model, criterion)\n",
    "        train_acc,trn_f1_sc = validate(train_loader, model, criterion)\n",
    "        che_saver.save_check(model,optimizer,scheduler,train_acc,val_acc,val_f1_sc,epoch)\n",
    "        scheduler.step()\n",
    "        recorder.record_info(epoch,train_loss,train_acc,val_acc,trn_f1_sc,val_f1_sc)\n",
    "        print(f'Epoch: {epoch:03}  Train Loss: {train_loss:.8f}  Train Acc: {train_acc:.6f} Train F1: {trn_f1_sc:.6f}  Val Acc: {val_acc:.6f} Val F1: {val_f1_sc:.6f}',end='\\r')\n",
    "        if train_loss < 1e-3 and trn_f1_sc == 1.:\n",
    "            break\n",
    "    print(' '*150,end='\\r')\n",
    "    print(f'Model: {pretrain}   KFold {i+1:02}/{n_splits}   Val Best Acc: {che_saver.val_best_acc:.6f} Val Best F1: {che_saver.val_best_f1sc:.6f}')\n",
    "    recorder.save_hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e23c5a7-5e4e-4220-8ad5-147c713f2991",
   "metadata": {},
   "source": [
    "### 训练曲线可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2625999c-a9f5-4627-88b8-1efdba278f12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91664c5-98fd-4b71-98ac-aa7b377856cc",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open(f'./logs/{recorder.fname}','r',encoding='utf-8')\n",
    "hist = eval(f.read())\n",
    "\n",
    "ep_arr = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "train_f1 = []\n",
    "val_f1 = []\n",
    "\n",
    "for ep,info in hist.items():\n",
    "    ep_arr.append(ep)\n",
    "    train_acc.append(info[1])\n",
    "    val_acc.append(info[2])\n",
    "    train_f1.append(info[3])\n",
    "    val_f1.append(info[4])\n",
    "\n",
    "plt.plot(ep_arr,train_acc,marker='x',label='train accuracy')\n",
    "plt.plot(ep_arr,val_acc,marker='o',label='val_accuracy')\n",
    "plt.plot(ep_arr,train_f1,marker='x',label='train f1 score')\n",
    "plt.plot(ep_arr,val_f1,marker='o',label='val f1 score')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef99492-8a21-43af-a9e3-54c5107bec92",
   "metadata": {},
   "source": [
    "### 模型测试与提交"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eec688-1071-460b-95c2-f93a9bf1a638",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(test_loader, model, criterion):\n",
    "    # model.eval()\n",
    "    val_acc = 0.0\n",
    "    \n",
    "    test_pred = []\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, target) in enumerate(test_loader):\n",
    "            inputs = inputs.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            output = model(inputs)\n",
    "            # output = F.normalize(output,dim=-1)\n",
    "            test_pred.append(output.data.cpu().numpy())\n",
    "            \n",
    "    return torch.Tensor(np.vstack(test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b081805-4827-4124-9f49-7dca4ac96901",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = pretrain\n",
    "model = model = XunFeiNet(name)\n",
    "\n",
    "# 由于训练集太少，为减少偶然性，使用增强的测试集\n",
    "pred = None\n",
    "for i in range(n_splits):\n",
    "    chep = torch.load(f'./model/{name}_kfold{i+1:02}_best.pth.tar')\n",
    "    model.load_state_dict(chep['state_dict'])\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    tmp = tmp = predict(test_loader, model, criterion)\n",
    "    print(f'KFold {i+1:02}/{n_splits}')\n",
    "    tmp = F.softmax(tmp,dim=-1)\n",
    "    if pred is None:\n",
    "        pred = tmp\n",
    "    else:\n",
    "        pred += tmp\n",
    "pred = pred.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a0e09-3ac6-4850-81a4-b1656ac220ab",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(\n",
    "    {\n",
    "        'uuid': [int(x.split('/')[-1][:-4]) for x in test_path],\n",
    "        'label': pred.argmax(1)\n",
    "})\n",
    "submit['label'] = submit['label'].map({1:'NC', 0: 'MCI'})\n",
    "submit = submit.sort_values(by='uuid')\n",
    "submit.to_csv('submit3_5.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245f458f-ed36-48c6-ab55-5514095b5e85",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aff9c4-1bf5-4c1a-9432-49b35a6b2744",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_best = pd.read_csv('./submit3_4.csv')\n",
    "pre_best['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f0aecb-c057-4dbc-a45e-71a8caf48c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
